{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dallah2002/a8alatr0clown/blob/main/Acquisition_Automatique_de_Donn%C3%A9es_Brevet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1><b>Acquisition automatique de Données : Brevet"
      ],
      "metadata": {
        "id": "JJBar6eBTfML"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "L'objectif principal de ce projet est d'automatiser la collecte et l'analyse de brevets concernant la 6G et la sécurité dans un fichier .csv, en se focalisant sur des brevets qu’on a retrouvé sur Google Patents, ensuite de créer une application qui permet la visualisation des données extraites dans le brevets."
      ],
      "metadata": {
        "id": "8OPX2_ZdUXLp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   <h2>Receuils des brevets\n",
        "\n"
      ],
      "metadata": {
        "id": "sv7iANjtWMY6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install aiohttp aiofiles"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "1G2K2r4tJjJx",
        "outputId": "1ca4ca24-1244-49d5-d955-6ddfc6108d1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (3.11.13)\n",
            "Collecting aiofiles\n",
            "  Downloading aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp) (2.5.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp) (1.18.3)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.11/dist-packages (from yarl<2.0,>=1.17.0->aiohttp) (3.10)\n",
            "Downloading aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: aiofiles\n",
            "Successfully installed aiofiles-24.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# Monter Google Drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7FhVZk_nJvBC",
        "outputId": "ed5af04b-c2e2-4cee-bff2-7227d8b590b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import aiohttp\n",
        "import asyncio\n",
        "from aiofiles import open as aio_open\n",
        "import time\n",
        "\n",
        "\n",
        "# --- CONSTANTES ---\n",
        "URL_BASE = \"https://patents.google.com/patent/US{}\"\n",
        "\n",
        "# Chemins des fichiers pour la gestion des brevets\n",
        "fichier_brevets = \"/content/drive/MyDrive/acquisitionbrevet/brevets/brevets_urls.txt\"\n",
        "fichier_csv = \"/content/drive/MyDrive/acquisitionbrevet/brevets/brevets_6G.csv\"\n",
        "fichier_brevets_traite = \"/content/drive/MyDrive/acquisitionbrevet/brevets/brevets_traite.txt\"\n",
        "fichier_dernier_brevet = \"/content/drive/MyDrive/acquisitionbrevet/brevets/dernier_brevet.txt\"\n",
        "\n",
        "# --- Mots-clés liés à la 6G ---\n",
        "MOTS_CLES_6G = [\n",
        "    \"terahertz communication\",\n",
        "    \"THz\",\n",
        "    \"massive MIMO\",\n",
        "    \"ultra-massive MIMO\",\n",
        "    \"reconfigurable intelligent surfaces\",\n",
        "    \"RIS\",\n",
        "    \"artificial intelligence\",\n",
        "    \"AI\",\n",
        "    \"machine learning\",\n",
        "    \"blockchain\",\n",
        "    \"distributed ledger technology\",\n",
        "    \"DLT\",\n",
        "    \"energy harvesting\",\n",
        "    \"quantum communication\",\n",
        "    \"non-terrestrial networks\",\n",
        "    \"NTN\",\n",
        "    \"visible light communication\",\n",
        "    \"VLC\",\n",
        "    \"orbital angular momentum\",\n",
        "    \"OAM\",\n",
        "    \"6G frequency bands\",\n",
        "    \"digital twins\",\n",
        "    \"photonic communication\",\n",
        "    \"holographic communication\",\n",
        "    \"self-sustaining networks\",\n",
        "    \"enhanced security and privacy\",\n",
        "    \"ultra-low latency\",\n",
        "    \"ultra-high speed\",\n",
        "    \"terabit-per-second\",\n",
        "    \"advanced beamforming\",\n",
        "    \"RIS channel modeling\",\n",
        "    \"RIS-network integration\",\n",
        "    \"Privacy\",\n",
        "    \"Data\",\n",
        "    \"Security\",\n",
        "    \"Privacy Policies\",\n",
        "    \"Device Sensors\",\n",
        "    \"Network Slicing\",\n",
        "    \"Edge Computing\",\n",
        "    \"Ultra-dense networks\",\n",
        "    \"Zero-touch networks\",\n",
        "    \"Massive IoT\",\n",
        "    \"Autonomous Vehicles\",\n",
        "    \"Smart Cities\",\n",
        "    \"Artificial General Intelligence\",\n",
        "    \"Self-Organizing Networks\",\n",
        "    \"Blockchain for Network Management\",\n",
        "    \"Direct Device-to-Device Communication\",\n",
        "    \"Cognitive Radio\",\n",
        "    \"Massive Cloud-RAN\",\n",
        "    \"Ambient Intelligence\",\n",
        "    \"Heterogeneous Networks\",\n",
        "    \"Molecular Communication\"\n",
        "]\n",
        "\n",
        "\n",
        "# --- FONCTION DE VALIDATION (ASYNCHRONE) ---\n",
        "async def est_brevet_valide(session, numero_brevet):\n",
        "    url = URL_BASE.format(numero_brevet)\n",
        "    try:\n",
        "        async with session.get(url, timeout=10) as reponse:\n",
        "            if reponse.status == 200:\n",
        "                contenu = await reponse.text()\n",
        "                if any(mot_cle in contenu.lower() for mot_cle in MOTS_CLES_6G):\n",
        "                    return url\n",
        "    except Exception as e:\n",
        "        print(f\"Erreur lors de la vérification du brevet {numero_brevet}: {e}\")\n",
        "    return None\n",
        "\n",
        "# --- CHARGEMENT DES URLS DÉJÀ ENREGISTRÉES ---\n",
        "async def charger_urls_existantes():\n",
        "    try:\n",
        "        async with aio_open(fichier_brevets_traite, \"r\") as f:\n",
        "            return {ligne.strip() for ligne in await f.readlines()}\n",
        "    except FileNotFoundError:\n",
        "        return set()\n",
        "\n",
        "# --- DÉTERMINER LE DERNIER NUMÉRO PARCOURU ---\n",
        "async def obtenir_dernier_brevet():\n",
        "    try:\n",
        "        async with aio_open(fichier_dernier_brevet, \"r\") as f:\n",
        "            dernier_numero = await f.read()\n",
        "            return int(dernier_numero.strip()) if dernier_numero.strip().isdigit() else 10318759\n",
        "    except Exception:\n",
        "        return 10318759\n",
        "\n",
        "# --- MISE À JOUR DES FICHIERS ---\n",
        "async def mettre_a_jour_fichiers(nouveaux_brevets, dernier_numero):\n",
        "    async with aio_open(fichier_brevets, \"a\") as f:\n",
        "        await f.writelines(f\"{url}\\n\" for url in nouveaux_brevets)\n",
        "\n",
        "    async with aio_open(fichier_brevets_traite, \"a\") as f:\n",
        "        await f.writelines(f\"{url}\\n\" for url in nouveaux_brevets)\n",
        "\n",
        "    async with aio_open(fichier_dernier_brevet, \"w\") as f:\n",
        "        await f.write(str(dernier_numero))\n",
        "\n",
        "# --- ACQUISITION ASYNCHRONE DES BREVETS ---\n",
        "async def acquisition_brevets(nombre_a_verifier):\n",
        "    debut_temps = time.time()\n",
        "\n",
        "    urls_traitees = await charger_urls_existantes()\n",
        "    dernier_brevet = await obtenir_dernier_brevet()\n",
        "\n",
        "    print(f\"Démarrage de la recherche à partir du numéro : {dernier_brevet}\")\n",
        "    nouveaux_brevets = []\n",
        "\n",
        "    async with aiohttp.ClientSession() as session:\n",
        "        taches = []\n",
        "        for i in range(nombre_a_verifier):\n",
        "            numero_courant = dernier_brevet + i\n",
        "            numero_brevet = f\"{numero_courant}B2\"\n",
        "\n",
        "            if any(numero_brevet in url for url in urls_traitees):\n",
        "                print(f\"🔁 Déjà traité pour US{numero_brevet}\")\n",
        "                continue\n",
        "\n",
        "            taches.append(est_brevet_valide(session, numero_brevet))\n",
        "\n",
        "        resultats = await asyncio.gather(*taches)\n",
        "\n",
        "        for url in resultats:\n",
        "            if url:\n",
        "                nouveaux_brevets.append(url)\n",
        "                print(f\"✅ Nouveau brevet trouvé : {url}\")\n",
        "\n",
        "    # Mise à jour des fichiers\n",
        "    await mettre_a_jour_fichiers(nouveaux_brevets, dernier_brevet + nombre_a_verifier)\n",
        "\n",
        "    # Résumé de l'exécution\n",
        "    fin_temps = time.time()\n",
        "    print(f\"🔍 Nombre total de brevets trouvés : {len(nouveaux_brevets)}\")\n",
        "    print(f\"⏱️ Temps total d'exécution : {fin_temps - debut_temps:.2f} secondes\")\n",
        "    print(\"🚀 Récupération des brevets terminée. Fichiers mis à jour.\")\n",
        "\n",
        "# --- EXÉCUTION DU SCRIPT ---\n",
        "await acquisition_brevets(nombre_a_verifier=100)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "HPGcVlRcJ0B9",
        "outputId": "f9289a32-df9e-4ef5-b806-933ac89fc1fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Démarrage de la recherche à partir du numéro : 10319059\n",
            "✅ Nouveau brevet trouvé : https://patents.google.com/patent/US10319064B2\n",
            "✅ Nouveau brevet trouvé : https://patents.google.com/patent/US10319066B2\n",
            "✅ Nouveau brevet trouvé : https://patents.google.com/patent/US10319069B2\n",
            "✅ Nouveau brevet trouvé : https://patents.google.com/patent/US10319070B2\n",
            "✅ Nouveau brevet trouvé : https://patents.google.com/patent/US10319073B2\n",
            "✅ Nouveau brevet trouvé : https://patents.google.com/patent/US10319075B2\n",
            "✅ Nouveau brevet trouvé : https://patents.google.com/patent/US10319076B2\n",
            "✅ Nouveau brevet trouvé : https://patents.google.com/patent/US10319080B2\n",
            "✅ Nouveau brevet trouvé : https://patents.google.com/patent/US10319086B2\n",
            "✅ Nouveau brevet trouvé : https://patents.google.com/patent/US10319092B2\n",
            "✅ Nouveau brevet trouvé : https://patents.google.com/patent/US10319093B2\n",
            "✅ Nouveau brevet trouvé : https://patents.google.com/patent/US10319095B2\n",
            "✅ Nouveau brevet trouvé : https://patents.google.com/patent/US10319096B2\n",
            "✅ Nouveau brevet trouvé : https://patents.google.com/patent/US10319100B2\n",
            "✅ Nouveau brevet trouvé : https://patents.google.com/patent/US10319107B2\n",
            "✅ Nouveau brevet trouvé : https://patents.google.com/patent/US10319109B2\n",
            "✅ Nouveau brevet trouvé : https://patents.google.com/patent/US10319112B2\n",
            "✅ Nouveau brevet trouvé : https://patents.google.com/patent/US10319115B2\n",
            "✅ Nouveau brevet trouvé : https://patents.google.com/patent/US10319119B2\n",
            "✅ Nouveau brevet trouvé : https://patents.google.com/patent/US10319120B2\n",
            "✅ Nouveau brevet trouvé : https://patents.google.com/patent/US10319125B2\n",
            "✅ Nouveau brevet trouvé : https://patents.google.com/patent/US10319128B2\n",
            "✅ Nouveau brevet trouvé : https://patents.google.com/patent/US10319129B2\n",
            "✅ Nouveau brevet trouvé : https://patents.google.com/patent/US10319130B2\n",
            "✅ Nouveau brevet trouvé : https://patents.google.com/patent/US10319141B2\n",
            "✅ Nouveau brevet trouvé : https://patents.google.com/patent/US10319143B2\n",
            "✅ Nouveau brevet trouvé : https://patents.google.com/patent/US10319144B2\n",
            "✅ Nouveau brevet trouvé : https://patents.google.com/patent/US10319146B2\n",
            "✅ Nouveau brevet trouvé : https://patents.google.com/patent/US10319147B2\n",
            "✅ Nouveau brevet trouvé : https://patents.google.com/patent/US10319152B2\n",
            "✅ Nouveau brevet trouvé : https://patents.google.com/patent/US10319157B2\n",
            "🔍 Nombre total de brevets trouvés : 31\n",
            "⏱️ Temps total d'exécution : 18.74 secondes\n",
            "🚀 Récupération des brevets terminée. Fichiers mis à jour.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "*    <h2> Extraction de données des brevets"
      ],
      "metadata": {
        "id": "bfGRyQS2L_He"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import aiofiles\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "\n",
        "# --- CONSTANTES ---\n",
        "BASE_URL = \"https://patents.google.com\"\n",
        "fichier_brevets = \"/content/drive/MyDrive/acquisitionbrevet/brevets/brevets_urls.txt\"\n",
        "fichier_csv = \"/content/drive/MyDrive/acquisitionbrevet/brevets/brevets_6G.csv\"\n",
        "\n",
        "# --- COLONNES DANS L'ORDRE DEMANDÉ ---\n",
        "COLUMNS = [\n",
        "    \"Lien\", \"Numéro Brevet\", \"Titre\", \"Date de publication\", \"Mots-clés\",\n",
        "    \"Description\", \"Domaine Technologique\", \"Inventeurs\", \"Titulaire du brevet\",\n",
        "    \"Statut du brevet\"\n",
        "]\n",
        "\n",
        "# --- Liste des stopwords à supprimer ---\n",
        "STOPWORDS = {\"a\", \"and\", \"that\", \"to\", \"be\", \"in\", \"the\", \"of\",\"an\",\"one\",\"present\",\"some\",\"for\",\"are\",\"is\",\"with\",\"this\",\"provided\",\"herein\",\"or\",\"more\",\"each\",\"includes\",\"include\"}\n",
        "\n",
        "# --- Charger les brevets déjà traités ---\n",
        "def load_processed_patents():\n",
        "    try:\n",
        "        df = pd.read_csv(fichier_csv)\n",
        "        return set(df[\"Numéro Brevet\"].dropna().unique())\n",
        "    except FileNotFoundError:\n",
        "        return set()\n",
        "\n",
        "\n",
        "# --- Détection du domaine technologique ---\n",
        "def detect_technology_field(title, abstract):\n",
        "    \"\"\" Catégorisation automatique des brevets selon leur domaine technologique. \"\"\"\n",
        "    keywords = {\n",
        "    \"Télécommunications\": [\n",
        "        \"5G\", \"6G\", \"network\", \"antenna\", \"MIMO\", \"massive MIMO\", \"ultra-massive MIMO\",\n",
        "        \"signal\", \"terahertz communication\", \"THz\", \"6G frequency bands\", \"advanced beamforming\",\n",
        "        \"RIS\", \"RIS channel modeling\", \"RIS-network integration\", \"non-terrestrial networks\", \"NTN\",\n",
        "        \"visible light communication\", \"VLC\", \"orbital angular momentum\", \"OAM\", \"ultra-high speed\",\n",
        "        \"terabit-per-second\", \"network slicing\", \"ultra-dense networks\", \"direct device-to-device communication\",\n",
        "        \"heterogeneous networks\", \"massive Cloud-RAN\"\n",
        "        ],\n",
        "    \"Intelligence Artificielle\": [\n",
        "        \"artificial intelligence\", \"AI\", \"machine learning\", \"deep learning\", \"neural network\",\n",
        "        \"artificial general intelligence\", \"ambient intelligence\", \"cognitive radio\", \"self-organizing networks\",\n",
        "        \"zero-touch networks\"\n",
        "        ],\n",
        "    \"Sécurité\": [\n",
        "        \"cryptography\", \"authentication\", \"security\", \"hacking\", \"protection\", \"enhanced security and privacy\",\n",
        "        \"privacy\", \"privacy policies\", \"data\", \"blockchain\", \"distributed ledger technology\", \"DLT\",\n",
        "        \"blockchain for network management\"\n",
        "        ],\n",
        "    \"Énergie\": [\n",
        "        \"battery\", \"energy\", \"recharge\", \"autonomy\", \"energy harvesting\", \"self-sustaining networks\"\n",
        "        ],\n",
        "    \"Quantique\": [\n",
        "        \"quantum\", \"qubit\", \"quantum communication\", \"molecular communication\"\n",
        "        ],\n",
        "    \"IoT et Réseaux\": [\n",
        "        \"massive IoT\", \"device sensors\", \"smart cities\", \"autonomous vehicles\", \"edge computing\"\n",
        "        ],\n",
        "    \"Communication Avancée\": [\n",
        "        \"photonic communication\", \"holographic communication\", \"digital twins\"\n",
        "        ]\n",
        "}\n",
        "\n",
        "    for field, words in keywords.items():\n",
        "        if any(word.lower() in (title + abstract).lower() for word in words):\n",
        "            return field\n",
        "    return \"Autre\"\n",
        "\n",
        "\n",
        "# --- EXTRACTION ASYNCHRONE DES BREVETS ---\n",
        "async def fetch_patent_details(session, url):\n",
        "    \"\"\" Récupère et extrait les informations principales d'un brevet. \"\"\"\n",
        "    try:\n",
        "        async with session.get(url, timeout=10) as response:\n",
        "            if response.status == 200:\n",
        "                content = await response.text()\n",
        "                soup = BeautifulSoup(content, \"html.parser\")\n",
        "\n",
        "                # 📌 Extraction du Titre via <meta name=\"DC.title\">\n",
        "                title_tag = soup.find(\"meta\", {\"name\": \"DC.title\"})\n",
        "                title = title_tag[\"content\"].strip() if title_tag else \"Non trouvé\"\n",
        "                patent_number = url.split(\"/\")[-1]\n",
        "                # 📌 Extraction de la Date de publication\n",
        "                pub_date = soup.find(\"meta\", {\"name\": \"DC.date\"})[\"content\"] if soup.find(\"meta\", {\"name\": \"DC.date\"}) else \"Non trouvé\"\n",
        "\n",
        "                # 📌 Récupération des inventeurs\n",
        "                inventors = \", \".join([tag.text.strip() for tag in soup.find_all(itemprop=\"inventor\")]) or \"Non trouvé\"\n",
        "\n",
        "                # 📌 Récupération du titulaire du brevet (anciennement \"Assignee\")\n",
        "                assignees = \", \".join([tag.text.strip() for tag in soup.find_all(itemprop=\"assigneeCurrent\")]) or \"Non trouvé\"\n",
        "\n",
        "                # 📌 Récupération du résumé (description)\n",
        "                abstract = soup.find(\"meta\", {\"name\": \"DC.description\"})[\"content\"] if soup.find(\"meta\", {\"name\": \"DC.description\"}) else \"Non trouvé\"\n",
        "\n",
        "                # 📌 Détection du domaine technologique\n",
        "                domain = detect_technology_field(title, abstract)\n",
        "\n",
        "                # 📌 Extraction du statut via itemprop \"legalStatusIfi\"\n",
        "                status_tag = soup.find(itemprop=\"legalStatusIfi\")\n",
        "                status = status_tag.text.strip() if status_tag else \"Inconnu\"\n",
        "\n",
        "                # 📌 Génération des mots-clés (filtrés)\n",
        "                words = [word for word in abstract.split()[:10] if word.lower() not in STOPWORDS]\n",
        "                keywords = \", \".join(words)\n",
        "\n",
        "\n",
        "\n",
        "                return {\n",
        "                    \"Lien\": url,\n",
        "                    \"Numéro Brevet\": patent_number,\n",
        "                    \"Titre\": title,\n",
        "                    \"Date de publication\": pub_date,\n",
        "                    \"Mots-clés\": keywords,\n",
        "                    \"Description\": abstract,\n",
        "                    \"Domaine Technologique\": domain,\n",
        "                    \"Inventeurs\": inventors,\n",
        "                    \"Titulaire du brevet\": assignees,\n",
        "                    \"Statut du brevet\": status\n",
        "                }\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Erreur lors de l'extraction de {url} : {e}\")\n",
        "    return None\n",
        "\n",
        "# --- CHARGER LES BREVETS TROUVÉS ---\n",
        "async def load_patent_urls():\n",
        "    try:\n",
        "        async with aiofiles.open(fichier_brevets, \"r\") as f:\n",
        "            urls = [line.strip() for line in await f.readlines() if line.strip()]\n",
        "            return urls\n",
        "    except FileNotFoundError:\n",
        "        print(\"📁 Fichier patent_urls.txt introuvable. Vérifie le chemin.\")\n",
        "        return []\n",
        "\n",
        "# --- SAUVEGARDE EN CSV ---\n",
        "async def save_to_csv(data):\n",
        "    df = pd.DataFrame(data, columns=COLUMNS)\n",
        "    try:\n",
        "        existing_df = pd.read_csv(fichier_csv)\n",
        "        df = pd.concat([existing_df, df], ignore_index=True)\n",
        "    except FileNotFoundError:\n",
        "        pass\n",
        "    df.to_csv(fichier_csv, index=False)\n",
        "    print(f\"✅ {len(data)} brevets ajoutés à {fichier_csv}\")\n",
        "\n",
        "# --- LANCEMENT DE L'EXTRACTION ---\n",
        "async def extract_patents_data():\n",
        "    urls = await load_patent_urls()\n",
        "    if not urls:\n",
        "        print(\"⚠️ Aucun brevet à extraire.\")\n",
        "        return\n",
        "\n",
        "    processed_patents = load_processed_patents()\n",
        "    urls_to_process = [url for url in urls if url.split(\"/\")[-1] not in processed_patents]\n",
        "\n",
        "    if not urls_to_process:\n",
        "        print(\"✅ Tous les brevets sont déjà traités.\")\n",
        "        return\n",
        "\n",
        "    print(f\"🔍 Extraction des données pour {len(urls_to_process)} brevets...\")\n",
        "\n",
        "    async with aiohttp.ClientSession() as session:\n",
        "        tasks = [fetch_patent_details(session, url) for url in urls_to_process]\n",
        "        results = await asyncio.gather(*tasks)\n",
        "\n",
        "    valid_results = [res for res in results if res is not None]\n",
        "    if valid_results:\n",
        "        await save_to_csv(valid_results)\n",
        "    else:\n",
        "        print(\"⚠️ Aucune donnée valide extraite.\")\n",
        "\n",
        "# --- EXÉCUTION DU SCRIPT ---\n",
        "await extract_patents_data()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "SOfWNUtGWrGW",
        "outputId": "77faafd5-a867-48be-8ed7-88415e26a58c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Extraction des données pour 90 brevets...\n",
            "❌ Erreur lors de l'extraction de https://patents.google.com/patent/US10319022B2 : \n",
            "❌ Erreur lors de l'extraction de https://patents.google.com/patent/US10318882B2 : \n",
            "❌ Erreur lors de l'extraction de https://patents.google.com/patent/US10318941B2 : \n",
            "✅ 87 brevets ajoutés à /content/drive/MyDrive/acquisitionbrevet/brevets/brevets_6G.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*    <h2> Ajouts des colonnes de Résumé, Problème et Solution aux données extraites"
      ],
      "metadata": {
        "id": "9rOYftbLMtte"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import pandas as pd\n",
        "import asyncio\n",
        "import json\n",
        "import aiohttp\n",
        "import nest_asyncio\n",
        "\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# --- CONFIGURATION ---\n",
        "API_KEY = \"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\"\n",
        "MODEL_ID = \"cognitivecomputations/dolphin3.0-r1-mistral-24b:free\"\n",
        "CSV_FILE = \"/content/drive/MyDrive/acquisitionbrevet/brevets/brevets_6G.csv\"\n",
        "BATCH_SIZE = 10  # Nombre de brevets à traiter par exécution\n",
        "\n",
        "PROMPT_TEMPLATE = \"\"\"\n",
        "Analyze the following patent description and extract:\n",
        "- Summary of the patent in 2 to 3 sentences.\n",
        "- Problem addressed\n",
        "- Solution provided\n",
        "\n",
        "Description:\n",
        "{content}\n",
        "\n",
        "Return the response in JSON format:\n",
        "{{\n",
        "  \"summary\": \"...\",\n",
        "  \"problem\": \"...\",\n",
        "  \"solution\": \"...\"\n",
        "}}\n",
        "\"\"\"\n",
        "\n",
        "# --- FONCTION D'ANALYSE ---\n",
        "async def analyze_patent(content):\n",
        "    \"\"\" Analyse un brevet et extrait Résumé, Problème et Solution via OpenRouter \"\"\"\n",
        "    if not content or pd.isna(content) or content.strip() == \"\":\n",
        "        return \"\", \"\", \"\"\n",
        "\n",
        "    prompt = PROMPT_TEMPLATE.format(content=content)\n",
        "\n",
        "    headers = {\n",
        "        \"Authorization\": f\"Bearer {API_KEY}\",\n",
        "        \"Content-Type\": \"application/json\"\n",
        "    }\n",
        "\n",
        "    payload = {\n",
        "        \"model\": MODEL_ID,\n",
        "        \"messages\": [\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ],\n",
        "        \"max_tokens\": 500\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        async with aiohttp.ClientSession() as session:\n",
        "            async with session.post(\"https://openrouter.ai/api/v1/chat/completions\", json=payload, headers=headers) as response:\n",
        "                response_json = await response.json()\n",
        "\n",
        "                if \"choices\" not in response_json:\n",
        "                    print(f\"⚠️ Réponse API invalide: {response_json}\")\n",
        "                    return \"\", \"\", \"\"\n",
        "\n",
        "                result = response_json[\"choices\"][0][\"message\"][\"content\"]\n",
        "\n",
        "                # Vérifie si la réponse est bien un JSON\n",
        "                try:\n",
        "                    data = json.loads(result)\n",
        "                except json.JSONDecodeError:\n",
        "                    print(f\"⚠️ Erreur JSON: Réponse brute non valide\\n{result}\")\n",
        "                    return \"\", \"\", \"\"\n",
        "\n",
        "                return data.get(\"summary\", \"\"), data.get(\"problem\", \"\"), data.get(\"solution\", \"\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Erreur API: {e}\")\n",
        "        return \"\", \"\", \"\"\n",
        "\n",
        "# --- TRAITEMENT CSV ---\n",
        "async def process_csv():\n",
        "    \"\"\" Charge le fichier CSV, analyse les brevets manquants et met à jour les résultats. \"\"\"\n",
        "    try:\n",
        "        df = pd.read_csv(CSV_FILE, dtype=str).fillna(\"\")\n",
        "    except FileNotFoundError:\n",
        "        print(f\"❌ Erreur: Fichier {CSV_FILE} introuvable.\")\n",
        "        return\n",
        "\n",
        "    # Ajouter les colonnes si elles n'existent pas\n",
        "    for col in [\"Résumé\", \"Problème\", \"Solution\"]:\n",
        "        if col not in df.columns:\n",
        "            df[col] = \"\"\n",
        "\n",
        "    # Sélection des brevets ayant au moins une colonne vide, et qui ne sont pas déjà complétés\n",
        "    to_analyze = df[(df[[\"Résumé\", \"Problème\", \"Solution\"]] == \"\").any(axis=1) & (df[\"Description\"].str.strip() != \"\")].head(BATCH_SIZE)\n",
        "\n",
        "    if to_analyze.empty:\n",
        "        print(\"✅ Tous les brevets ont déjà été analysés !\")\n",
        "        return\n",
        "\n",
        "    print(f\"🔍 Nombre de brevets à analyser: {len(to_analyze)}\")\n",
        "\n",
        "    tasks = []\n",
        "    indices = []\n",
        "\n",
        "    for idx, row in to_analyze.iterrows():\n",
        "        description = row[\"Description\"]\n",
        "        if description.strip():  # Vérifier que la description n'est pas vide\n",
        "            tasks.append(analyze_patent(description))\n",
        "            indices.append(idx)\n",
        "        else:\n",
        "            print(f\"⚠️ Brevet {idx} ignoré car sans description.\")\n",
        "\n",
        "    # Exécuter les requêtes en parallèle\n",
        "    results = await asyncio.gather(*tasks)\n",
        "\n",
        "    # Mise à jour du DataFrame avec les résultats uniquement si la colonne est vide\n",
        "    for idx, (summary, problem, solution) in zip(indices, results):\n",
        "        if df.at[idx, \"Résumé\"] == \"\":\n",
        "            df.at[idx, \"Résumé\"] = summary\n",
        "        if df.at[idx, \"Problème\"] == \"\":\n",
        "            df.at[idx, \"Problème\"] = problem\n",
        "        if df.at[idx, \"Solution\"] == \"\":\n",
        "            df.at[idx, \"Solution\"] = solution\n",
        "\n",
        "    # Sauvegarde propre du fichier sans écraser les données existantes\n",
        "    try:\n",
        "        df.to_csv(CSV_FILE, index=False, encoding='utf-8')\n",
        "        print(f\"✅ Mise à jour terminée ! {len(indices)} brevets analysés.\")\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Erreur d'écriture du fichier CSV: {e}\")\n",
        "\n",
        "# --- EXECUTION ---\n",
        "await process_csv()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ah6eVNcTzzk6",
        "outputId": "4c5358f7-6c89-4a50-f9cb-2546d9df9881",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "❌ Erreur: Fichier /content/drive/MyDrive/acquisitionbrevet/brevets/brevets_6G.csv introuvable.\n"
          ]
        }
      ]
    }
  ]
}